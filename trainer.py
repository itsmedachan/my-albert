from tokenizer import SentencePieceTokenizer

en_tokenizer = SentencePieceTokenizer("en_path指定")
ja_tokenizer = SentencePieceTokenizer("ja_path指定")
